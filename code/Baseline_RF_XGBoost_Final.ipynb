{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d54d3660-ad2e-4d64-8a2f-42ac78ebe5bb",
   "metadata": {},
   "source": [
    "## Random Forest and XGBoost as a baseline predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ce11454-9822-4a1c-ba0f-5ce42484255b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure  # for the shap plots\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, matthews_corrcoef, accuracy_score, precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedGroupKFold, GridSearchCV\n",
    "import torch\n",
    "import xgboost as xgb\n",
    "import shap   # explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38903ba-c82e-4994-bd12-fb2be7ba2a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/baseline_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd921c24-f673-4a01-9468-f8876db16f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert features and labels into torch tensors\n",
    "features = df.iloc[:, 3:len(df.columns)-1] \n",
    "X = torch.tensor(features.values)\n",
    "X = X.to(torch.float)  \n",
    "columns = list(df.columns.values)[3:len(df.columns)-1]\n",
    "print(columns)\n",
    "y = torch.tensor(df[\"label\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b282470-b574-4750-8698-edf5ab09bf8b",
   "metadata": {},
   "source": [
    "### Stratified K-Fold sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65939c7c-66de-43d4-bd92-0d6050977392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, validation and test sets\n",
    "\n",
    "def kfold_new(train_value, val_value):\n",
    "    global train, val, test, train_val, train_labels, val_labels, test_labels\n",
    "    train, val, test, train_val = [], [], [], []\n",
    "    train_labels, val_labels, test_labels = [], [], []\n",
    "    \n",
    "    kf = StratifiedGroupKFold(n_splits=train_value, shuffle=False)\n",
    "    groups = df[\"drugcomb_sorted\"].to_list() \n",
    "    \n",
    "    # train/val: 90%, test: 10% -> first split\n",
    "    for i, (train_val_idx, test_idx) in enumerate(kf.split(X, y, groups)): \n",
    "        print(f\"Fold {i+1}:\")\n",
    "        print(f\" Train and Validation: index={train_val_idx[:20]}\")  # 80%\n",
    "        \n",
    "        train_val_groups = np.array(groups)[train_val_idx.astype(int)]\n",
    "        train_val_y = df.iloc[train_val_idx][\"label\"]\n",
    "\n",
    "        # add the indices and labels\n",
    "        train_val.append(train_val_idx)\n",
    "        test.append(test_idx)\n",
    "        test_labels.append(df.iloc[test_idx][\"label\"].values)\n",
    "        \n",
    "        # train: 80%, val: 10% -> second split\n",
    "        inner_skf = StratifiedGroupKFold(n_splits=val_value, shuffle=False) \n",
    "        train_idx, val_idx = next(inner_skf.split(df.iloc[train_val_idx], train_val_y, train_val_groups))    \n",
    "\n",
    "        # combine train and validation indies\n",
    "        arr1, arr2 = train_idx, val_idx\n",
    "        arr = [*arr1, *arr2]\n",
    "        arr.sort()\n",
    "\n",
    "        # create dictionary for the mapping\n",
    "        list1 = arr  # new index\n",
    "        list2 = train_val_idx  # old index\n",
    "        d1 = {}\n",
    "        for i in range(len(list1)):  # everything: train + val\n",
    "            d1[list1[i]] = list2[i]\n",
    "\n",
    "        # convert the new to the original indices \n",
    "        old_idx = []   \n",
    "        old_idx_ = []\n",
    "        for i in range(len(train_idx)):\n",
    "            old_idx.append(d1.get(train_idx[i])) \n",
    "\n",
    "        for i in range(len(val_idx)):\n",
    "            old_idx_.append(d1.get(val_idx[i])) \n",
    "\n",
    "        # check whether the 3 sets have overlapping elements\n",
    "        \"\"\"print(\"Check for any overlap between train and validation\")\n",
    "        print(list(set(old_idx).intersection(old_idx_)))\n",
    "\n",
    "        print(\"Check for any overlap between train and test\")\n",
    "        print(list(set(old_idx).intersection(test_idx)))\n",
    "\n",
    "        print(\"Check for any overlap between validation and test\")\n",
    "        print(list(set(old_idx_).intersection(test_idx)))\"\"\"\n",
    " \n",
    "        print(f\"     Train: index={old_idx[:20]}, length={len(old_idx)}\") \n",
    "        print(f\"     Validation: index={old_idx_[:20]}, length={len(old_idx_)}\") \n",
    "        \n",
    "        train.append(old_idx)\n",
    "        train_labels.append(df.iloc[old_idx][\"label\"].values)  \n",
    "        val.append(old_idx_)\n",
    "        val_labels.append(df.iloc[old_idx_][\"label\"].values) \n",
    "\n",
    "        print(f\" Test:  index={test_idx[:20]}, length={len(test_idx)}\")  # 10% of the total\n",
    "        print(\"*\"*100)\n",
    "\n",
    "# 80% train, 10% val, 10% test (final version)\n",
    "kfold_new(10,9)\n",
    "\n",
    "# 70% train, 10% validation, 20% test \n",
    "#kfold_new(5,8)\n",
    "\n",
    "# 60% train, 20% val, 20% test\n",
    "# kfold_new(5,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0056ac-ab53-4570-a482-4cad5374815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test sets (old version without validation set)\n",
    "\n",
    "\"\"\"\n",
    "k = 5  \n",
    "k_fold = StratifiedGroupKFold(n_splits=k, shuffle=False) \n",
    "groups = df[\"drugcomb_sorted\"].to_list()   # avoid data leakage\n",
    "\n",
    "train_arr = []\n",
    "test_arr = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(k_fold.split(X, y, groups)):\n",
    "    print(f\"Fold {i+1}:\")\n",
    "    print(f\" Train: index={train_index}\")\n",
    "    print(f\" Test:  index={test_index}\")\n",
    "    train_features = df.iloc[train_index][columns]\n",
    "    #print(train_features)\n",
    "    train_arr.append(df.iloc[train_index][\"label\"].values)\n",
    "    test_arr.append(df.iloc[test_index][\"label\"].values)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdea723-cd88-4f4b-91c4-8ef779e76916",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd7f5fd-d3eb-46d1-9998-8f06e75808f6",
   "metadata": {},
   "source": [
    "### Grid search and hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af728978-59a8-445b-99c8-4af7fd4c27b7",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1951aee-3234-4232-bf5a-3ab203ce8c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'n_estimators': [50, 100, 150],    # Number of trees in the forest\n",
    "    'max_depth': [10, 15, 20],       \n",
    "    'min_samples_split': [2, 10],        # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [2, 5],          # Minimum number of samples required to be at a leaf node\n",
    "    'max_features': ['sqrt', 'log2', None]}\n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(random_forest, param_grid, cv=5, scoring=\"matthews_corrcoef\", verbose=3, return_train_score=False)  # cv = cross validation sets\n",
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c814cba4-2529-4bb5-b9ac-6dfed669dc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_\n",
    "\"\"\"\n",
    "{'max_depth': 10,\n",
    " 'max_features': 'log2',\n",
    " 'min_samples_leaf': 5,\n",
    " 'min_samples_split': 10,\n",
    " 'n_estimators': 100}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea44ebf1-6357-49b5-b74b-67ebdf9e296f",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f566e779-8d4e-4b89-b597-82f08521850c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost = xgb.XGBClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306f1407-1be8-4bcd-822e-3542971f237a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search / hyperparameter tuning\n",
    "param_grid2 = [\n",
    "    {'eta': [0.1,0.4,0.7],         \n",
    "    'max_depth': [10,15,20],       \n",
    "    'max_leaf_nodes': [8,16,32,64],    \n",
    "    'gamma': [0.4,0.6,0.8],\n",
    "    'n_estimators': [50,100,150],\n",
    "    'lambda': [0,0.5,1]}\n",
    "]\n",
    "\n",
    "grid_search2 = GridSearchCV(xgboost, param_grid2, cv=5, scoring=\"matthews_corrcoef\", verbose=3, return_train_score=False)  # cv = number of folds\n",
    "grid_search2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5af6d5d-702f-44e0-988f-b1daf85ff7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_\n",
    "\"\"\"\n",
    "{'eta': 0.1,\n",
    " 'gamma': 0.4,\n",
    " 'lambda': 0.5,\n",
    " 'max_depth': 20,\n",
    " 'max_leaf_nodes': 8,\n",
    " 'n_estimators': 150}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb215f9-5ade-415e-afda-ee78234c273b",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34052521-cc68-4c3a-8d3b-e1c0d4d8e25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizations = \"../visualizations\"\n",
    "if not os.path.exists(visualizations):\n",
    "    os.makedirs(visualizations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2335be5-847c-4ba3-b868-940fd2a1dd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, validation and test data\n",
    "train_pred = []\n",
    "val_pred = []\n",
    "test_pred = []\n",
    "\n",
    "# initialized the classifier in each fold to avoid overfitting\n",
    "for i in range(len(train)):\n",
    "    print(f\"********** Fold {i+1}: **********\")    \n",
    "    # choose either the random forest or xgboost model\n",
    "    classifier = RandomForestClassifier(max_depth=15, min_samples_leaf=2, class_weight=\"balanced\")\n",
    "    #classifier = xgb.XGBClassifier(eta=0.7, gamma=0.4, reg_lambda=None, max_depth=30, max_leaf_nodes=None, n_estimators=150)\n",
    "    \n",
    "    train_features = torch.tensor(df.iloc[train[i]][columns].values)\n",
    "    train_features = train_features.to(torch.float) \n",
    "    train_label = torch.tensor(df.iloc[train[i]][\"label\"].values)\n",
    "    train_label = train_label.to(torch.long)\n",
    "\n",
    "    # train data\n",
    "    classifier.fit(train_features, train_label)\n",
    "    pred = classifier.predict(train_features)\n",
    "    train_pred.append(pred)\n",
    "    print(\"Train accuracy:\", accuracy_score(train_label, pred))\n",
    "    print(\"MCC:\", matthews_corrcoef(train_label, pred))\n",
    "    cm1 = confusion_matrix(train_label, train_pred[i])\n",
    "    ConfusionMatrixDisplay(cm1).plot() \n",
    "\n",
    "    # save the random forest or xgboost result\n",
    "    #plt.savefig(f\"{visualizations}/Confusion matrix RF train - fold {i+1}.png\")  \n",
    "    #plt.savefig(f\"{visualizations}/Confusion matrix XGB train - fold {i+1}.png\")   \n",
    "    \n",
    "    # validation data\n",
    "    val_features = torch.tensor(df.iloc[val[i]][columns].values)\n",
    "    val_features = val_features.to(torch.float) \n",
    "    val_label = torch.tensor(df.iloc[val[i]][\"label\"].values)\n",
    "    val_label = val_label.to(torch.long)\n",
    "    val_ = classifier.predict(val_features)\n",
    "    val_pred.append(val_)\n",
    "    print(\"Validation accuracy:\", accuracy_score(val_label, val_pred[i]))\n",
    "    print(\"MCC:\", matthews_corrcoef(val_label, val_pred[i]))\n",
    "    cm2 = confusion_matrix(val_label, val_pred[i])\n",
    "    ConfusionMatrixDisplay(cm2).plot()  \n",
    "\n",
    "    #plt.savefig(f\"{visualizations}/Confusion matrix RF validation - fold {i+1}.png\")  \n",
    "    #plt.savefig(f\"{visualizations}/Confusion matrix XGB validation - fold {i+1}.png\")  \n",
    "    \n",
    "    # test data\n",
    "    test_features = torch.tensor(df.iloc[test[i]][columns].values)\n",
    "    test_features = test_features.to(torch.float)         \n",
    "    test_label = torch.tensor(df.iloc[test[i]][\"label\"].values)\n",
    "    test_label = test_label.to(torch.long)\n",
    "    pred_ = classifier.predict(test_features)\n",
    "    test_pred.append(pred_)\n",
    "    print(\"Test accuracy:\", accuracy_score(test_label, test_pred[i])) \n",
    "    print(\"MCC:\", matthews_corrcoef(test_label, test_pred[i]))   \n",
    "    cm3 = confusion_matrix(test_label, test_pred[i]) \n",
    "    ConfusionMatrixDisplay(cm3).plot()\n",
    "\n",
    "    #plt.savefig(f\"{visualizations}/Confusion matrix RF test - fold {i+1}.png\")  \n",
    "    #plt.savefig(f\"{visualizations}/Confusion matrix XGB test - fold {i+1}.png\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a98dad-126a-4212-ac46-5d3bf8d210d8",
   "metadata": {},
   "source": [
    "## Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18007084-cc45-4084-844b-de02eae140be",
   "metadata": {},
   "source": [
    "#### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78b332b-98a2-4777-91a4-71b8d507a9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = classifier.feature_importances_\n",
    "feature_imp_df = pd.DataFrame({'Feature': feature_columns, 'Gini Importance': importances}).sort_values('Gini Importance', ascending=False) \n",
    "print(feature_imp_df)\n",
    "\n",
    "#feature_imp_df.to_csv(\"Feature_Importance_RF.csv\", index=False)\n",
    "#feature_imp_df.to_csv(\"Feature_Importance_XGB.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bebafa-eb95-4b31-9bf2-af6990786086",
   "metadata": {},
   "source": [
    "#### Shapley values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0d6ea6-2be2-4f61-a99e-e3bb6c9aed65",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs() \n",
    "\n",
    "# choose the best fold: the best test folds below have the MCC score of 0.19\n",
    "n = 9 # random forest: test fold 10\n",
    "#n = 4   # xgboost: test fold 5\n",
    "\n",
    "test_shap = df.iloc[test[n]][columns]  # fold 9 in the test set had the best MCC score\n",
    "explainer = shap.TreeExplainer(classifier) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9716e67-832f-4fa2-b085-1d8b4bba41d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer.shap_values(test_shap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a16b22a-37af-4b6d-92dd-cbc9f2134a9f",
   "metadata": {},
   "source": [
    "#### Decision Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0a3cac-0e75-4435-b3d2-106aa2781eb9",
   "metadata": {},
   "source": [
    "#### Array structure of the shap_values in the random forest classifier\n",
    "When plotting, only use one column, e.g. shap_values[:,:,0] or shap_values[:,:,1]\n",
    "\n",
    "print(shap_values[:,:,0])   # column 0: class 0, column 1: class 1, first index: sample, second index: feature, third index: column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82fc5cc-3401-4c11-b124-2322c33bf198",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(explainer.expected_value)\n",
    "print(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5233a370-d9d3-4d95-ad1d-f9bd5c7941c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = figure(figsize=(30, 30), dpi=80)   # specify output figure size\n",
    "# random forest\n",
    "# positive values\n",
    "shap.decision_plot(explainer.expected_value[0], shap_values[n][:, 0], test_shap.iloc[n], ignore_warnings=True, show=False) \n",
    "fig.tight_layout()   \n",
    "#fig.savefig(\"shap_decision_plot_RF.png\")\n",
    "\n",
    "# negative values\n",
    "shap.decision_plot(explainer.expected_value[1], shap_values[n][:, 1], test_shap.iloc[n], ignore_warnings=True, show=False) \n",
    "fig.tight_layout()  \n",
    "#fig.savefig(\"shap_decision_plot2_RF.png\")\n",
    "\n",
    "# xgboost\n",
    "shap.decision_plot(explainer.expected_value, shap_values, test_shap.iloc[n], ignore_warnings=True, show=False)  # ignore_warnings to plot more samples\n",
    "fig.tight_layout()   # avoid labels being cut off\n",
    "#fig.savefig(\"shap_decision_plot_XGB.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a29660f-27fc-4c17-b438-c484dfb1bf60",
   "metadata": {},
   "source": [
    "#### Bar plot: absolute values of shapley values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cbebdd-1b2d-47af-84b4-5924d0adb8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest\n",
    "shap.summary_plot(shap_values[:,:,0], features.iloc[test[n]], plot_type=\"bar\", show=False)\n",
    "plt.savefig(\"shap_bar.png\")\n",
    "\n",
    "# xgboost\n",
    "#shap.summary_plot(shap_values, features.iloc[test[n]], plot_type=\"bar\", show=False)\n",
    "#plt.savefig(\"shap_bar_XGB.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456db46a-dd7f-421c-a8c4-168c3c1dadff",
   "metadata": {},
   "source": [
    "#### Summary plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96291cf-0fad-4d1e-96f0-66d59bb3de8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest\n",
    "shap.summary_plot(shap_values[:,:,0], features.iloc[test[n]], show=False) \n",
    "plt.savefig('shap.png')\n",
    "\n",
    "# xgboost\n",
    "#shap.summary_plot(shap_values, features.iloc[test[n]], show=False) \n",
    "#plt.savefig('shap_XGB.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a6d72f-d077-4f87-98ba-dc45320f2911",
   "metadata": {},
   "source": [
    "#### Force plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f377f1f-e873-442b-9a6b-5a61f89cae08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explanations for one instance\n",
    "# random forest\n",
    "force_plot_rf1 = shap.force_plot(explainer.expected_value[0], shap_values[9][:, 0], test_shap.iloc[0], show=False) \n",
    "# shap.save_html(\"force_plot.html\", force_plot_rf1)  # the plot doesn't get exported with plt.savefig and only produces an empty file\n",
    "force_plot_rf2 = shap.force_plot(explainer.expected_value[1], shap_values[9][:, 1], test_shap.iloc[0], show=False) \n",
    "# shap.save_html(\"force_plot2.html\", force_plot_rf2)\n",
    "\n",
    "# xgboost\n",
    "force_plot_xgb = shap.force_plot(explainer.expected_value, shap_values[n], test_shap.iloc[0], show=False) \n",
    "#shap.save_html(\"force_plot_XGB.html\", force_plot_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fa9d64-b92d-480a-952d-85e3151c61b9",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "Create confusion matrices and evaluation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1a35b6-8cd3-4b7f-aa1f-40969254fcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(test_labels, test_pred):\n",
    "    global data\n",
    "    mcc_, precision_, recall_, accuracy_ = [], [], [], []\n",
    "    for i in range(10):\n",
    "        mcc = matthews_corrcoef(test_labels[i], test_pred[i])\n",
    "        precision = precision_score(test_labels[i], test_pred[i])\n",
    "        recall = recall_score(test_labels[i], test_pred[i])\n",
    "        accuracy = accuracy_score(test_labels[i], test_pred[i])\n",
    "        mcc_.append(mcc)\n",
    "        precision_.append(precision)\n",
    "        recall_.append(recall)\n",
    "        accuracy_.append(accuracy)\n",
    "        \n",
    "        cm = confusion_matrix(test_labels[i], test_pred[i])\n",
    "        ConfusionMatrixDisplay(cm).plot()\n",
    "        \n",
    "    data = [mcc_, precision_, recall_, accuracy_]\n",
    "    return data\n",
    "\n",
    "# export the train/validation/test evaluation\n",
    "#evaluation(train_labels, train_pred)\n",
    "#evaluation(val_labels, val_pred)\n",
    "evaluation(test_labels, test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f18ddaa-3550-4026-b202-fbe918df5430",
   "metadata": {},
   "source": [
    "### Export results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bad297b-83fa-434a-82f0-b5a223ab0ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_columns = [\"MCC\", \"Precision\", \"Recall\", \"Accuracy\"]\n",
    "\n",
    "def export_results(model, data, eval_columns):\n",
    "    evaluation = \"../evaluation\"\n",
    "    if not os.path.exists(evaluation):\n",
    "        os.makedirs(evaluation)\n",
    "        \n",
    "    df_results = pd.DataFrame()\n",
    "    for i in range(len(data)):\n",
    "        df_results[eval_columns[i]] = pd.Series(data[i])\n",
    "    \n",
    "    df_results.index += 1 \n",
    "    df_results.to_csv(f\"{evaluation}/{model}.csv\", index_label=\"ID\")\n",
    "    return df_results\n",
    "\n",
    "# random forest\n",
    "export_results(\"Random_Forest_Train\", data, eval_columns)\n",
    "export_results(\"Random_Forest_Validation\", data, eval_columns)\n",
    "export_results(\"Random_Forest_Test\", data, eval_columns)\n",
    "    \n",
    "# xgboost\n",
    "#export_results(\"XGB_Train\", data, eval_columns)\n",
    "#export_results(\"XGB_Validation\", data, eval_columns)\n",
    "#export_results(\"XGB_Test\", data, eval_columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be201a3-27a6-4349-be0f-6fafa9df1919",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
