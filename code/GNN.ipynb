{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6961c84-572b-4ef1-897c-b28cd2fef0d3",
   "metadata": {},
   "source": [
    "## GNN for drug-drug combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df80254-58ed-48b3-b829-02254691228d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure  # for the shap plots\n",
    "import random\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, matthews_corrcoef, precision_score, recall_score, accuracy_score\n",
    "from sklearn.model_selection import StratifiedGroupKFold, ParameterGrid\n",
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn.conv import GCNConv, GATConv, TransformerConv\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric import seed_everything\n",
    "from shap import KernelExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2677389c-967a-484a-ab1f-ff8dbab9ab10",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizations = \"../visualizations\"\n",
    "if not os.path.exists(visualizations):\n",
    "    os.makedirs(visualizations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c1b9ed-27c1-40fe-980f-f88066fa6f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(42)  # random seed for train/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8221979e-2ad5-4ac0-b67c-32dff8b03282",
   "metadata": {},
   "source": [
    "### Datasets with new ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f940aba-4827-4786-bb94-ee459ff759e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the node and edge features specified in Feature_selection.ipynb\n",
    "nodes = pd.read_csv(\"../data/gnn_node_features.csv\")   # took the op feature out\n",
    "edges = pd.read_csv(\"../data/gnn_edge_features.csv\")   # took the op feature out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e0c832-efa7-489c-959b-979efa11a2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert node and edge features into two lists\n",
    "def nodes_edges(nodes, edges):\n",
    "    global edge_features, node_features\n",
    "    edge_arr = edges.columns[5:len(edges.columns)-1].to_list()  # excluding ID\n",
    "    edge_features = []\n",
    "    for i in range(len(edge_arr)):\n",
    "        edge_features.append(edges[edge_arr[i]])\n",
    "\n",
    "    node_arr = nodes.columns[2:].to_list()  # excluding ID\n",
    "    node_features = []\n",
    "    for i in range(len(node_arr)):\n",
    "        node_features.append(nodes[node_arr[i]])\n",
    "\n",
    "nodes_edges(nodes, edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a76db61-b248-4f96-972e-d2bda0cca99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on the number of nodes and edges, convert them into tensors \n",
    "def dataset():\n",
    "    x = torch.tensor(node_features, dtype=torch.float32).t()\n",
    "    edge_index = torch.tensor([edges[\"drugA_ID\"], edges[\"drugB_ID\"]], dtype=torch.int64)\n",
    "    edge_attr = torch.tensor(edge_features, dtype=torch.float).t()\n",
    "    edge_labels = torch.tensor(edges[edges.columns[-1]], dtype=torch.long)\n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, edge_labels=edge_labels)\n",
    "graph_data = dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db44cf82-a05b-4c8f-b2f3-0d32c3c992d8",
   "metadata": {},
   "source": [
    "### From PyTorch Geometric's documentation:\n",
    "- https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html\n",
    "- x = Node feature matrix with shape [num_nodes, num_node_features]\n",
    "- edge_index = Graph connectivity in COO format with shape [2, num_edges]\n",
    "- edge_attr = Edge feature matrix with shape [num_edges, num_edge_features]\n",
    "- y = Graph-level or node-level ground-truth labels, but for link classification tasks, use edge_labels\n",
    "- output: Data(x=[4412, 8], edge_index=[2, 95986], edge_attr=[95986, 6], edge_labels=[95986]) (doubling the edges to ensure the graph is undirected)\n",
    "- index with 8 node attributes, connectivity, 6 edge attributes and 95986 directed edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2368ef5e-7708-47cf-8366-da6e6e203619",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_edge_features = graph_data.edge_attr.shape[-1] \n",
    "num_edge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e2814f-3c90-463d-bb8e-b163ce0cf063",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data.edge_index.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9460cb9a-63cf-45ad-81ca-5fe5c439b9a4",
   "metadata": {},
   "source": [
    "### Graph properties\n",
    "Check if the graph is directed. If not, then process the data to ensure the undirectedness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0557fc95-0cc5-4792-a099-f4a23f2e1229",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data.has_isolated_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2be60d-d5aa-4e1f-ae31-375aae0964ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data.has_self_loops()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af693447-8274-4da1-bd99-2eba4ef6f7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data.is_directed()  # ensure this outputs False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef87be36-f026-4ba5-ae81-9853cae6ab30",
   "metadata": {},
   "source": [
    "## Graph architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69669a60-0818-4383-9832-700c22997845",
   "metadata": {},
   "source": [
    "### Set seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac1d11c-d051-428c-bcf7-10d75ddc0233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    random.seed(seed)\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "\n",
    "set_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e116eeda-7de8-4f03-89fb-929b8c602b90",
   "metadata": {},
   "source": [
    "### Stratified Group K-Fold cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9e1ee7-54aa-4ef4-811c-78495994b1de",
   "metadata": {},
   "source": [
    "### Train/validation/test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11297e8d-01bd-47cb-8f8c-319dab7b339d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {float:left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12838742-aa34-4848-8892-c001749ce3a7",
   "metadata": {},
   "source": [
    "### Idea of k-fold cross-validation: example with k=5 with 70% train, 10% validation and 20% test data\n",
    "The models were initially trained with k=5. However, the GCN didn't classify anything into class 1 during most of the folds, k=10 is used for all models and the 80/10/10 split was used in the end for evaluation. \n",
    "\n",
    "First split:\n",
    "| Fold 1 | Fold 2 |\tFold 3 | Fold 4 | Fold 5 |\n",
    "| -------- | ------- | ------- |  ------- | ------- | \n",
    "| Train/validation | Train/validation | Train/validation | Train/validation | Test |\n",
    "| Test | Train/validation | Train/validation | Train/validation | Train/validation |\n",
    "| Train/validation | Test| Train/validation | Train/validation | Train/validation |\n",
    "| Train/validation | Train/validation | Test | Train/validation |  Train/validation |\n",
    "| Train/validation | Train/validation | Train/validation | Test | Train/validation |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb30ad16-1c7c-4cb9-a28e-e19e01eb08b9",
   "metadata": {},
   "source": [
    "In the second split, the data looks like this:  \n",
    "| Fold 1 | Fold 2 |\tFold 3 | Fold 4 | Fold 5 | Fold 6 | Fold 7 | Fold 8\n",
    "| -------- | ------- | ------- |  ------- | ------- | ------- | ------- | ------- | \n",
    "| Train | Train | Train | Train | Train | Train | Train | Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e565e911-def2-435c-abd5-40607f8cd5b1",
   "metadata": {},
   "source": [
    "The final result: \n",
    "| Fold 1 | Fold 2 |\tFold 3 | Fold 4 | Fold 5\n",
    "| -------- | ------- | ------- |  ------- | ------- | \n",
    "| Train | Train | Train | Validation | Test | \n",
    "| Test | Train | Train | Train | Validation |\n",
    "| Validation | Test | Train | Train |  Train |\n",
    "| Train | Validation | Test | Train | Train |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbd4225-100f-463d-b670-8ff6ba7c0762",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train, validation and test sets \n",
    "def kfold_new(train_value, val_value):\n",
    "    global train, val, test, train_val, train_labels, val_labels, test_labels\n",
    "    train, val, test, train_val = [], [], [], []\n",
    "    train_labels, val_labels, test_labels = [], [], []\n",
    "    \n",
    "    kf = StratifiedGroupKFold(n_splits=train_value, shuffle=False)\n",
    "    groups = edges[\"drugcomb_sorted\"].to_list() \n",
    "    \n",
    "    # train/val: 90%, test: 10% -> first split\n",
    "    for i, (train_val_idx, test_idx) in enumerate(kf.split(graph_data.edge_index.t(), graph_data.edge_labels, groups)): \n",
    "        print(f\"Fold {i+1}:\")\n",
    "        print(f\" Train and Validation: index={train_val_idx[:20]}\") \n",
    "        \n",
    "        train_val_groups = np.array(groups)[train_val_idx.astype(int)]\n",
    "        train_val_y = graph_data.edge_labels[train_val_idx]\n",
    "\n",
    "        # add the indices and labels\n",
    "        train_val.append(train_val_idx)\n",
    "        test.append(test_idx)\n",
    "        test_labels.append(graph_data.edge_labels[test_idx])\n",
    "        \n",
    "        # train: 80%, val: 10% -> second split\n",
    "        inner_skf = StratifiedGroupKFold(n_splits=val_value, shuffle=False) \n",
    "        train_idx, val_idx = next(inner_skf.split(graph_data.edge_index[:, train_val_idx].t(), train_val_y, train_val_groups))    \n",
    "\n",
    "        # combine train and validation indies\n",
    "        arr1, arr2 = train_idx, val_idx\n",
    "        arr = [*arr1, *arr2]\n",
    "        arr.sort()\n",
    "\n",
    "        # create dictionary for the mapping\n",
    "        list1 = arr  # new index\n",
    "        list2 = train_val_idx  # old index\n",
    "        d1 = {}\n",
    "        for i in range(len(list1)):  # everything: train + val\n",
    "            d1[list1[i]] = list2[i]\n",
    "\n",
    "        # convert the new to the original indices \n",
    "        old_idx = []   \n",
    "        old_idx_ = []\n",
    "        for i in range(len(train_idx)):\n",
    "            old_idx.append(d1.get(train_idx[i])) \n",
    "\n",
    "        for i in range(len(val_idx)):\n",
    "            old_idx_.append(d1.get(val_idx[i])) \n",
    "\n",
    "        # check whether the 3 sets have overlapping elements\n",
    "        \"\"\"print(\"Check for any overlap between train and validation\")\n",
    "        print(list(set(old_idx).intersection(old_idx_)))\n",
    "\n",
    "        print(\"Check for any overlap between train and test\")\n",
    "        print(list(set(old_idx).intersection(test_idx)))\n",
    "\n",
    "        print(\"Check for any overlap between validation and test\")\n",
    "        print(list(set(old_idx_).intersection(test_idx)))\"\"\"\n",
    " \n",
    "        print(f\"     Train: index={old_idx[:20]}, length={len(old_idx)}\") \n",
    "        print(f\"     Validation: index={old_idx_[:20]}, length={len(old_idx_)}\") \n",
    "        \n",
    "        train.append(old_idx)\n",
    "        train_labels.append(graph_data.edge_labels[old_idx])\n",
    "        val.append(old_idx_)\n",
    "        val_labels.append(graph_data.edge_labels[old_idx_])\n",
    "\n",
    "        print(f\" Test:  index={test_idx[:20]}, length={len(test_idx)}\")  # 10% of the total\n",
    "        print(\"*\"*100)\n",
    "\n",
    "# different combinations\n",
    "# 80% train, 10% val, 10% test\n",
    "kfold_new(10,9)\n",
    "\n",
    "# ------ previous tests -------\n",
    "# 70% train, 10% val, 20% test \n",
    "# kfold_new(5,8)\n",
    "\n",
    "# 60% train, 20% val, 20% test -> doesn't work that well and almost no labels got classified correctly into class 1\n",
    "# kfold_new(5,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0749514-da91-46b9-a559-1c563455df0d",
   "metadata": {},
   "source": [
    "### Graph Convolutional Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2833520d-b0ef-43d0-92be-c785d0dcbdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(MessagePassing):  # node features and edge indices only, GCN -> GCN -> Linear -> Softmax probabilities -> Output class\n",
    "    def __init__(self, dim_in, dim_h1, dim_h2=4):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(dim_in, dim_h1)\n",
    "        self.conv2 = GCNConv(dim_h1, dim_h2)\n",
    "        self.linear = Linear(dim_h2, 2) \n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        x = self.propagate(edge_index, x=x)  # message passing\n",
    "        return x\n",
    "\n",
    "    def decode(self, z, edge_index):\n",
    "        out = self.linear(edge_feat)\n",
    "        out = torch.softmax(out, dim=1)\n",
    "        return out\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        global edge_feat\n",
    "        z = self.encode(x, edge_index)\n",
    "        x_src, x_dst = z[edge_index[0]], z[edge_index[1]]\n",
    "        edge_feat = torch.cat([x_src + x_dst], dim=-1)  # map node embeddings into edge predictions, added them to ensure permutation invariance\n",
    "        return self.decode(z, edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda51a5e-9590-4be7-a013-ebb53b9326fd",
   "metadata": {},
   "source": [
    "### Graph Attention Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba61fd14-53ac-4832-9266-aa3bb0394923",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(MessagePassing):\n",
    "    def __init__(self, edge_attr, dim_in, dim_h1, dim_h2=4):\n",
    "        super().__init__()\n",
    "        self.gat1 = GATConv(dim_in, dim_h1, edge_dim=edge_attr)\n",
    "        self.gat2 = GATConv(dim_h1, dim_h2, edge_dim=edge_attr)\n",
    "        self.linear = Linear(dim_h2 + edge_attr, 2)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        x = self.gat1(x, edge_index, edge_attr=edge_attr).relu()\n",
    "        x = self.gat2(x, edge_index, edge_attr=edge_attr).relu()\n",
    "\n",
    "        x = self.propagate(edge_index, x=x, edge_attr=edge_attr)  # add message passing\n",
    "        x_src, x_dst = x[edge_index[0]], x[edge_index[1]] \n",
    "        edge_feat = torch.cat([x_src + x_dst, edge_attr], dim=-1)  # adding edge features into the final prediction\n",
    "        out = self.linear(edge_feat) \n",
    "        out = torch.softmax(out, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addf3ade-4477-4256-8c12-9db0ec14b37a",
   "metadata": {},
   "source": [
    "### Graph Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd776494-e51b-4fd5-b34c-8e21361ce067",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(MessagePassing):\n",
    "    def __init__(self, edge_attr, dim_in, dim_h1, dim_h2=4):\n",
    "        super().__init__()\n",
    "        self.gat1 = TransformerConv(dim_in, dim_h1, edge_dim=edge_attr)\n",
    "        self.gat2 = TransformerConv(dim_h1, dim_h2, edge_dim=edge_attr)\n",
    "        self.linear = Linear(dim_h2 + edge_attr, 2)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        x = self.gat1(x, edge_index, edge_attr=edge_attr).relu()\n",
    "        x = self.gat2(x, edge_index, edge_attr=edge_attr).relu()\n",
    "\n",
    "        x = self.propagate(edge_index, x=x, edge_attr=edge_attr)  # add message passing\n",
    "        x_src, x_dst = x[edge_index[0]], x[edge_index[1]]\n",
    "        edge_feat = torch.cat([x_src + x_dst, edge_attr], dim=-1)  # adding edge features into the final prediction\n",
    "        out = self.linear(edge_feat)\n",
    "        out = torch.softmax(out, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26341bcf-af26-4ea1-be1d-7d22f0c5f7ea",
   "metadata": {},
   "source": [
    "### Training loop, validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98d2f17-1957-4bc1-b27b-29683c715829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, lr, weight_decay, weighted_loss, edge_attr, epochs=30):\n",
    "    global train_prediction, val_pred, train_loss, val_loss, train_acc, val_acc, mcc_final\n",
    "    train_prediction, val_pred = [], []\n",
    "    train_loss, val_loss, train_acc, val_acc = [], [], [], []\n",
    "\n",
    "    weights = torch.tensor([1, weighted_loss])  # class 1 is the minority class so it's higher weighted\n",
    "    weights = weights.to(torch.float)\n",
    "    loss_fn = CrossEntropyLoss(weight=weights)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay) \n",
    "\n",
    "    for i in range(len(train)): \n",
    "        print(f\"********** Fold {i+1} train data: **********\")\n",
    "        train_edge_index = graph_data.edge_index[:, train[i]]\n",
    "        train_labels = graph_data.edge_labels[train[i]]\n",
    "        val_edge_index = graph_data.edge_index[:, val[i]]\n",
    "        val_labels = graph_data.edge_labels[val[i]]\n",
    "        \n",
    "        # initialize validation set with another stratified group k fold \n",
    "        for epoch in range(epochs + 1):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if edge_attr:   # GAT, GT\n",
    "                train_edge_attr = graph_data.edge_attr[train[i]]\n",
    "                output = model(graph_data.x, train_edge_index, train_edge_attr)\n",
    "            else:    # GCN\n",
    "                output = model(graph_data.x, train_edge_index)\n",
    "            \n",
    "            loss = loss_fn(output, train_labels)  # target value is edge classification\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if epoch % 10 == 0: \n",
    "                # evaluate train data\n",
    "                accuracy = torch.sum(torch.argmax(output, dim=1) == train_labels) / len(train_labels)\n",
    "                train_prediction_ = output.argmax(1)\n",
    "                mcc_train = matthews_corrcoef(train_labels, train_prediction_)\n",
    "                \n",
    "                print(f\"Epoch: {epoch}\")\n",
    "                print(\" Train data: \")\n",
    "                print(f\"   Loss: {loss}\")\n",
    "                print(f\"   Accuracy: {accuracy}\") \n",
    "                print(f\"   MCC: {mcc_train}\")\n",
    "\n",
    "                # evaluate validation data\n",
    "                if edge_attr:\n",
    "                    val_edge_attr = graph_data.edge_attr[val[i]]\n",
    "                    val_out = model(graph_data.x, val_edge_index, val_edge_attr)\n",
    "                else:\n",
    "                    val_out = model(graph_data.x, val_edge_index)\n",
    "                    \n",
    "                loss_ = loss_fn(val_out, val_labels)\n",
    "                val_accuracy = torch.sum(torch.argmax(val_out, dim=1) == val_labels) / len(val_labels)\n",
    "                val_pred_ = val_out.argmax(1)\n",
    "                val_mcc = matthews_corrcoef(val_labels, val_pred_)\n",
    "                \n",
    "                print(\"Validation data: \")\n",
    "                print(f\"   Loss: {loss_}\")\n",
    "                print(f\"   Accuracy: {val_accuracy}\")\n",
    "                print(f\"   MCC: {val_mcc}\")\n",
    "\n",
    "                if epoch == 30:\n",
    "                    # append train data results\n",
    "                    train_loss.append(loss.detach().numpy())\n",
    "                    train_acc.append(accuracy.detach().numpy())\n",
    "                    train_prediction.append(output.argmax(1))\n",
    "\n",
    "                    # append validation data results                    \n",
    "                    val_loss.append(loss_.detach().numpy())\n",
    "                    val_acc.append(val_accuracy.detach().numpy())\n",
    "                    val_pred.append(val_out.argmax(1))    \n",
    "\n",
    "                    cm = confusion_matrix(train_labels, train_prediction[i])\n",
    "                    cm2 = confusion_matrix(val_labels, val_pred[i])\n",
    "                    ConfusionMatrixDisplay(cm).plot()  \n",
    "                    \n",
    "                    plt.savefig(f\"{visualizations}/GCN Fold {i+1} Train.svg\")\n",
    "                    #plt.savefig(f\"{visualizations}/GAT Fold {i+1} Train.svg\")\n",
    "                    #plt.savefig(f\"{visualizations}/GT Fold {i+1} Train.svg\")\n",
    "                    \n",
    "                    #print(\"*\"*100)\n",
    "                    ConfusionMatrixDisplay(cm2).plot()                    \n",
    "                    plt.savefig(f\"{visualizations}/GCN Fold {i+1} Validation.svg\")\n",
    "                    #plt.savefig(f\"{visualizations}/GAT Fold {i+1} Validation.svg\")\n",
    "                    #plt.savefig(f\"{visualizations}/GT Fold {i+1} Validation.svg\")\n",
    "                    \n",
    "                # use MCC score to evaluate the model\n",
    "                if epoch == 30 and i == 9:   # assume that the last epoch and last fold has the best score\n",
    "                    mcc_final = matthews_corrcoef(val_labels, val_pred[i])  \n",
    "                    print(f\"    MCC Final: {mcc_final}\")\n",
    "        \n",
    "    return mcc_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fd1cb5-a672-45e0-88d6-04aa0b455907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, edge_attr):\n",
    "    global pred_test\n",
    "    pred_test = []\n",
    "\n",
    "    #weights = torch.tensor([1, weighted_loss])  \n",
    "    #weights = weights.to(torch.float)\n",
    "    #loss_fn = CrossEntropyLoss(weight=weights)\n",
    "\n",
    "    for i in range(len(test)):\n",
    "        print(f\"********** Fold {i+1} test data: **********\")\n",
    "        test_edge_index = graph_data.edge_index[:, test[i]]\n",
    "        test_labels = graph_data.edge_labels[test[i]]\n",
    "\n",
    "        if edge_attr:   # GAT and GT\n",
    "            test_edge_attr = graph_data.edge_attr[test[i]]\n",
    "            output = model(graph_data.x, test_edge_index, test_edge_attr)\n",
    "        else:   # GCN\n",
    "            output = model(graph_data.x, test_edge_index)\n",
    "        \n",
    "        pred_test.append(output.argmax(1))\n",
    "        #loss = loss_fn(output, test_labels)\n",
    "        accuracy = torch.sum(torch.argmax(output, dim=1) == test_labels) / len(test_labels)\n",
    "        mcc_test = matthews_corrcoef(test_labels, pred_test[i])\n",
    "       \n",
    "        print(\"Test data:\")\n",
    "        #print(f\"   Loss: {loss}\")\n",
    "        print(f\"   Accuracy: {accuracy}\")\n",
    "        print(f\"   MCC: {mcc_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03da12dc-c1d0-4058-b187-f7acd6cfe0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this for every GNN model\n",
    "\"\"\"\n",
    "Initial parameter grid\n",
    "param_grid = {\n",
    "    'hidden_channels': [8, 16, 32, 64],\n",
    "    'learning_rate': [0.01, 0.001, 0.0001],\n",
    "    'weight_decay': [5e-4, 1e-4],\n",
    "    'weighted_loss': [80, 100, 120, 140, 160, 180, 200, 220],\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# final parameter grid\n",
    "param_grid = {\n",
    "    'hidden_channels': [8, 16],\n",
    "    'learning_rate': [0.001, 0.0001],\n",
    "    'weight_decay': [5e-4, 1e-4],\n",
    "    'weighted_loss': [100, 120, 140, 160, 180, 200],\n",
    "}\n",
    "\n",
    "grid = ParameterGrid(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dabda43-52fc-4299-87a8-5f9f78733849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding best hyperparameters\n",
    "best_val_acc = -np.inf\n",
    "best_params = None\n",
    "\n",
    "for params in grid:\n",
    "    print(f\"Hyperparameters: weighted_loss={params['weighted_loss']}, hidden_channels={params['hidden_channels']}, learning_rate={params['learning_rate']}, weight_decay={params['weight_decay']}\")\n",
    "\n",
    "    # choose a model from below:\n",
    "    #model = GCN(graph_data.num_node_features, params['hidden_channels'])\n",
    "    #model = GAT(num_edge_features, graph_data.num_features, params['hidden_channels'])\n",
    "    model = Transformer(num_edge_features, graph_data.num_features, params['hidden_channels'])\n",
    "\n",
    "    # choose a training function from below:\n",
    "    # GCN\n",
    "    #fit(model, params['learning_rate'], params['weight_decay'], params['weighted_loss'], False)\n",
    "    # GAT and GT\n",
    "    fit(model, params['learning_rate'], params['weight_decay'], params['weighted_loss'], True)\n",
    "    \n",
    "    # find best hyperparameters using the MCC score\n",
    "    if mcc_final > best_val_acc:\n",
    "        best_val_acc = mcc_final\n",
    "        best_params = params\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}, Best Validation Accuracy: {best_val_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f02f35c-e70f-4196-a6c2-270a59fbcaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best hyperparameters for GCN\n",
    "# Best Hyperparameters: {'hidden_channels': 16, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'weighted_loss': 120}, \n",
    "# Best Validation Accuracy: 0.08698340010113292"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d81422-d491-4fd7-b735-f171affb1754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best hyperparameters for GAT\n",
    "# Best Hyperparameters: {'hidden_channels': 8, 'learning_rate': 0.001, 'weight_decay': 0.0001, 'weighted_loss': 120}, \n",
    "# Best Validation Accuracy: 0.03473767142951595"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c214061a-ed19-4322-98ef-21318691c813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best hyperparameters for GT\n",
    "# Best Hyperparameters: {'hidden_channels': 16, 'learning_rate': 0.001, 'weight_decay': 0.0001, 'weighted_loss': 100}, \n",
    "# Best Validation Accuracy: 0.06322532092824903"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a3038c-91f2-469d-8422-b64d886e0eea",
   "metadata": {},
   "source": [
    "### Test the models using the best hyperparameters obtained from ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab2dcd8-a04f-4b6c-9a10-c019b5f21caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(graph_data.num_node_features, 16)\n",
    "fit(model, 0.001, 0.0005, 110, False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64b806f-53c0-4361-9a41-abedfd8afc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(model, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9f65ac-595e-4138-a0a7-61682194f8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "gat_model = GAT(num_edge_features, graph_data.num_features, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb429488-d867-4406-ae19-add19cb2ec41",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(gat_model, 0.001, 0.0005, 90, True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74fa2b8-27a9-4bd4-8f12-f28020d9e134",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(gat_model, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ba8140-6fd7-48e3-aa71-aa726828707a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(num_edge_features, graph_data.num_features, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d1a6bc-e538-4854-99de-1f45a12934e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(transformer, 0.001, 0.0005, 100, True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efff8341-eab6-4213-b44a-28add148bbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(transformer, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996cac9f-6ff8-4749-ba80-55be77969713",
   "metadata": {},
   "source": [
    "### Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54bc8f0-9b18-45e9-af21-48293462048d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm_test(n):\n",
    "    for i in range(n):\n",
    "        cm = confusion_matrix(test_labels[i], pred_test[i])\n",
    "        mcc = matthews_corrcoef(test_labels[i], pred_test[i])\n",
    "        print(mcc)\n",
    "        ConfusionMatrixDisplay(cm).plot()\n",
    "        \n",
    "        plt.savefig(f\"{visualizations}/Confusion matrix GCN - fold {i+1} Test.png\")\n",
    "        #plt.savefig(f\"{visualizations}/Confusion matrix GAT - fold {i+1} Test.png\")\n",
    "        #plt.savefig(f\"{visualizations}/Confusion matrix GT - fold {i+1} Test.png\")\n",
    "\n",
    "cm_test(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8516de11-b67e-4c08-93b7-d831d184655b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(test_arr, pred_test):\n",
    "    global data\n",
    "    mcc_gcn, precision_gcn, recall_gcn, accuracy_gcn = [], [], [], []\n",
    "    for i in range(10):\n",
    "        mcc = matthews_corrcoef(test_arr[i], pred_test[i])\n",
    "        precision = precision_score(test_arr[i], pred_test[i])\n",
    "        recall = recall_score(test_arr[i], pred_test[i])\n",
    "        accuracy = accuracy_score(test_arr[i], pred_test[i])\n",
    "\n",
    "        mcc_gcn.append(mcc)\n",
    "        precision_gcn.append(precision)\n",
    "        recall_gcn.append(recall)\n",
    "        accuracy_gcn.append(accuracy)\n",
    "    data = [mcc_gcn, precision_gcn, recall_gcn, accuracy_gcn]\n",
    "    return data\n",
    "\n",
    "# export the train/validation/test evaluation\n",
    "#evaluation(train_labels, train_prediction)\n",
    "#evaluation(val_labels, val_pred)\n",
    "evaluation(test_labels, pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd8ba20-fd08-411a-a292-bb406616b254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the evaluation scores into a csv file\n",
    "eval_columns = [\"MCC\", \"Precision\", \"Recall\", \"Accuracy\"]\n",
    "\n",
    "def export_results(model, data, columns):\n",
    "    evaluation = \"../evaluation\"\n",
    "    if not os.path.exists(evaluation):\n",
    "        os.makedirs(evaluation)\n",
    "        \n",
    "    df = pd.DataFrame()\n",
    "    for i in range(len(data)):\n",
    "        df[columns[i]] = pd.Series(data[i])\n",
    "    \n",
    "    df.index += 1 \n",
    "    df.to_csv(f\"{evaluation}/{model}.csv\", index_label=\"ID\")\n",
    "    return df\n",
    "\n",
    "export_results(\"GCN_Test\", data, eval_columns) \n",
    "#export_results(\"GAT_Test\", data, eval_columns) \n",
    "#export_results(\"GT_Test\", data, eval_columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5bccac-f266-46c0-9b45-5b4e7189f0c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
