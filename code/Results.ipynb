{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28b5b76f-d903-4ce2-9e19-53be7c09b115",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce85a70-ef27-4242-b226-97338321c21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, matthews_corrcoef "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb21c5b4-5795-4409-a8da-4da9d43c39c8",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f550a09-6f87-48c2-b8e1-21b920641fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = \"../evaluation\"\n",
    "\n",
    "# train\n",
    "df1_train = pd.read_csv(f\"{evaluation}/GCN_Train.csv\").drop(\"ID\", axis=1).head(10)\n",
    "df2_train = pd.read_csv(f\"{evaluation}/GAT_Train.csv\").drop(\"ID\", axis=1).head(10)\n",
    "df3_train = pd.read_csv(f\"{evaluation}/GT_Train.csv\").drop(\"ID\", axis=1).head(10)\n",
    "df4_train = pd.read_csv(f\"{evaluation}/NN_Train.csv\").drop(\"ID\", axis=1).head(10) \n",
    "df5_train = pd.read_csv(f\"{evaluation}/Random_Forest_Train.csv\").drop(\"ID\", axis=1).head(10)\n",
    "df6_train = pd.read_csv(f\"{evaluation}/XGB_Train.csv\").drop(\"ID\", axis=1).head(10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f30d01-20e2-4724-a2b1-0dc18581e28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation\n",
    "df1_val = pd.read_csv(f\"{evaluation}/GCN_Validation.csv\").drop(\"ID\", axis=1).head(10) \n",
    "df2_val = pd.read_csv(f\"{evaluation}/GAT_Validation.csv\").drop(\"ID\", axis=1).head(10) \n",
    "df3_val = pd.read_csv(f\"{evaluation}/GT_Validation.csv\").drop(\"ID\", axis=1).head(10) \n",
    "df4_val = pd.read_csv(f\"{evaluation}/NN_Validation.csv\").drop(\"ID\", axis=1).head(10) \n",
    "df5_val = pd.read_csv(f\"{evaluation}/Random_Forest_Validation.csv\").drop(\"ID\", axis=1).head(10) \n",
    "df6_val = pd.read_csv(f\"{evaluation}/XGB_Validation.csv\").drop(\"ID\", axis=1).head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248eaba8-bbcf-4840-b6b3-6e98af18a2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "df1_test = pd.read_csv(f\"{evaluation}/GCN_Test.csv\").drop(\"ID\", axis=1).head(10) \n",
    "df2_test = pd.read_csv(f\"{evaluation}/GAT_Test.csv\").drop(\"ID\", axis=1).head(10) \n",
    "df3_test = pd.read_csv(f\"{evaluation}/GT_Test.csv\").drop(\"ID\", axis=1).head(10) \n",
    "df4_test = pd.read_csv(f\"{evaluation}/NN_Test.csv\").drop(\"ID\", axis=1).head(10) \n",
    "df5_test = pd.read_csv(f\"{evaluation}/Random_Forest_Test.csv\").drop(\"ID\", axis=1).head(10) \n",
    "df6_test = pd.read_csv(f\"{evaluation}/XGB_Test.csv\").drop(\"ID\", axis=1).head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c076fff-ded0-40b7-b9a3-31317d76be1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38f96b4-fda3-4aa5-923b-8aa0aa166a32",
   "metadata": {},
   "source": [
    "### Calculate mean and standard deviation for the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cc6ab8-5203-40c0-98a3-c75f0e6be328",
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = [\"MCC\", \"Precision\", \"Recall\", \"Accuracy\"]\n",
    "\n",
    "def calculate_avg_std(criteria, name, *models):\n",
    "    average = {}\n",
    "    standard_deviation = {}\n",
    "    for i in range(len(name)):  # initialize dictionary\n",
    "        average[name[i]] = None\n",
    "        standard_deviation[name[i]] = None\n",
    "\n",
    "    for i in range(len(models)):  # append mean and std\n",
    "        avg = models[i].mean(axis=0)\n",
    "        std = models[i].std(axis=0)\n",
    "\n",
    "        # add the avg and std to every model for each criteria\n",
    "        average[name[i]] = [[criteria[j], avg[j]] for j in range(len(criteria))]\n",
    "        standard_deviation[name[i]] = [[criteria[j], std[j]] for j in range(len(criteria))]\n",
    "            \n",
    "    print(\"Average:\", average)\n",
    "    print(\"*\"*20)\n",
    "    print(\"Standard deviation:\", standard_deviation)\n",
    "    print(\"*\"*20)\n",
    "    return average, standard_deviation\n",
    "\n",
    "calculate_avg_std(criteria, [\"GCN\", \"GAT\", \"Transformer\", \"NN\", \"RF\", \"XGB\"], df1_train, df2_train, df3_train, df4_train, df5_train, df6_train)\n",
    "calculate_avg_std(criteria, [\"GCN\", \"GAT\", \"Transformer\", \"NN\", \"RF\", \"XGB\"], df1_test, df2_test, df3_test, df4_test, df5_test, df6_test)\n",
    "calculate_avg_std(criteria, [\"GCN\", \"GAT\", \"Transformer\", \"NN\", \"RF\", \"XGB\"], df1_val, df2_val, df3_val, df4_val, df5_val, df6_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9459544a-452c-4420-a8c6-3e27d2e4807a",
   "metadata": {},
   "source": [
    "### Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4efbd54-b814-43a6-8f45-49d3155afc86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# take any number of baseline/non-baseline models and one criteria from the following: MCC, accuracy, precision, recall\n",
    "# only one metric is taken at once because of readability\n",
    "criteria = [\"MCC\", \"Precision\", \"Recall\", \"Accuracy\"]\n",
    "def plot_results(name, criteria, *models):  # name of plot, evaluation criteria and any number of models to be plotted as a box plot\n",
    "    labels = [name[i] for i in range(len(name))]\n",
    "\n",
    "    # get the scores for all models specified\n",
    "    results = []\n",
    "    for i in range(len(models)):\n",
    "        results.append(models[i][f\"{criteria[0]}\"])\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_ylabel('Score')\n",
    "    bplot = ax.boxplot(results, \n",
    "    patch_artist=True,  # fill with color\n",
    "    tick_labels=labels, showmeans=True)  # will be used to label x-ticks\n",
    "    plt.title(f\"{criteria[0]}\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.subplots_adjust(bottom=0.3)  # so that the labels aren't cut off\n",
    "    plt.savefig(f\"{evaluation}/Evaluation result: {criteria[0]}.svg\")\n",
    "    plt.show()    \n",
    "\n",
    "for i in range(len(criteria)):\n",
    "    plot_results([\"GCN\", \"GAT\", \"Graph Transformer\", \"Neural Network\", \"Random Forest\", \"XGBoost\"], [criteria[i]], df1_test, df2_test, df3_test, df4_test, df5_test, df6_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faa5de0-7566-4b4a-b45f-68a7bf31cd33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
