{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77e475c6-0ac2-4873-8b13-1962b23fc1ea",
   "metadata": {},
   "source": [
    "## Neural Network as a baseline predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df65006-0f69-4b6f-89f7-002ef48db285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, matthews_corrcoef, precision_score, recall_score, accuracy_score\n",
    "from sklearn.model_selection import StratifiedGroupKFold, ParameterGrid\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea20dfc-3714-4652-a62d-e9b855a9af9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizations = \"../visualizations\"\n",
    "if not os.path.exists(visualizations):\n",
    "    os.makedirs(visualizations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea271a59-7cb2-455f-9e4d-708adc5afbd2",
   "metadata": {},
   "source": [
    "### Loading data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b166cf0-feed-487f-ad3d-d8d6a1ddcb17",
   "metadata": {},
   "source": [
    "The file structure of ``baseline_features.csv``: drugcomb_sorted, drugA, drugB, m edge features, n node features for drug A, n node features for drug B, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7d291d-0158-4615-9a14-6b1c6ad1c2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/baseline_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473ea9a6-8149-4997-a331-94f3af4b4f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5632f9c6-6ca4-4f94-9a03-d2f4655d0f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.iloc[:, 3:len(df.columns)-1] \n",
    "X = torch.tensor(features.values)\n",
    "X = X.to(torch.float)  # convert to float so it's compatible with the neural network\n",
    "columns = list(df.columns.values)[3:len(df.columns)-1]\n",
    "print(columns)\n",
    "y = torch.tensor(df[\"label\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67458b61-5ac0-4ef4-b140-9ef4a2809924",
   "metadata": {},
   "source": [
    "### Stratified 10-fold cross-validation with train, validation and test sets<a class=\"anchor\" id=\"crossvalidation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e658e77-6cbd-48e0-a2e8-c1665b684ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_new(train_value, val_value):\n",
    "    global train, val, test, train_val, train_labels, val_labels, test_labels\n",
    "    train, val, test, train_val = [], [], [], []\n",
    "    train_labels, val_labels, test_labels = [], [], []\n",
    "    \n",
    "    kf = StratifiedGroupKFold(n_splits=train_value, shuffle=False)\n",
    "    groups = df[\"drugcomb_sorted\"].to_list() \n",
    "    \n",
    "    # train/val: 80%, test: 20% -> first split\n",
    "    for i, (train_val_idx, test_idx) in enumerate(kf.split(X, y, groups)): \n",
    "        print(f\"Fold {i+1}:\")\n",
    "        print(f\" Train and Validation: index={train_val_idx[:20]}\")  # 80%\n",
    "        \n",
    "        train_val_groups = np.array(groups)[train_val_idx.astype(int)]\n",
    "        train_val_y = df.iloc[train_val_idx][\"label\"]\n",
    "\n",
    "        # add the indices and labels\n",
    "        train_val.append(train_val_idx)\n",
    "        test.append(test_idx)\n",
    "        test_labels.append(df.iloc[test_idx][\"label\"].values)\n",
    "        \n",
    "        # train: 60%, val: 20% -> second split\n",
    "        inner_skf = StratifiedGroupKFold(n_splits=val_value, shuffle=False)  # train: 60%, val: 20%\n",
    "        train_idx, val_idx = next(inner_skf.split(df.iloc[train_val_idx], train_val_y, train_val_groups))    \n",
    "\n",
    "        # combine train and validation indies\n",
    "        arr1, arr2 = train_idx, val_idx\n",
    "        arr = [*arr1, *arr2]\n",
    "        arr.sort()\n",
    "\n",
    "        # create dictionary for the mapping\n",
    "        list1 = arr  # new index\n",
    "        list2 = train_val_idx  # old index\n",
    "        d1 = {}\n",
    "        for i in range(len(list1)):  # everything: train + val\n",
    "            d1[list1[i]] = list2[i]\n",
    "\n",
    "        # convert the new to the original indices \n",
    "        old_idx = []   \n",
    "        old_idx_ = []\n",
    "        for i in range(len(train_idx)):\n",
    "            old_idx.append(d1.get(train_idx[i])) \n",
    "\n",
    "        for i in range(len(val_idx)):\n",
    "            old_idx_.append(d1.get(val_idx[i])) \n",
    "\n",
    "        # check whether the 3 sets have overlapping elements\n",
    "        \"\"\"print(\"Check for any overlap between train and validation\")\n",
    "        print(list(set(old_idx).intersection(old_idx_)))\n",
    "\n",
    "        print(\"Check for any overlap between train and test\")\n",
    "        print(list(set(old_idx).intersection(test_idx)))\n",
    "\n",
    "        print(\"Check for any overlap between validation and test\")\n",
    "        print(list(set(old_idx_).intersection(test_idx)))\"\"\"\n",
    " \n",
    "        print(f\"     Train: index={old_idx[:20]}, length={len(old_idx)}\") \n",
    "        print(f\"     Validation: index={old_idx_[:20]}, length={len(old_idx_)}\") \n",
    "        \n",
    "        train.append(old_idx)\n",
    "        train_labels.append(df.iloc[old_idx][\"label\"].values)  \n",
    "        val.append(old_idx_)\n",
    "        val_labels.append(df.iloc[old_idx_][\"label\"].values) \n",
    "\n",
    "        print(f\" Test:  index={test_idx[:20]}, length={len(test_idx)}\")  # 20% of the total\n",
    "        print(\"*\"*100)\n",
    "\n",
    "# 80% train, 10% val, 10% test\n",
    "kfold_new(10,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9bb554-ed1d-4084-9d67-2f9c4989a503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold(n):  # old version with only train and test sets (maybe delete this later?)\n",
    "    k = 5  \n",
    "    k_fold = StratifiedGroupKFold(n_splits=k, shuffle=False) \n",
    "    groups = df[\"drugcomb_sorted\"].to_list()   # avoid data leakage\n",
    "\n",
    "    train, val, test = [], [], []\n",
    "    train_arr = []\n",
    "    val_arr = []\n",
    "    test_arr = []\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(k_fold.split(X, y, groups)):\n",
    "        print(f\"Fold {i+1}:\")\n",
    "        print(f\" Train: index={train_index}\")\n",
    "        print(f\" Test:  index={test_index}\")\n",
    "        train_features = df.iloc[train_index][columns]\n",
    "        train_arr.append(df.iloc[train_index][\"label\"].values)\n",
    "        test_arr.append(df.iloc[test_index][\"label\"].values)\n",
    "\n",
    "#k_fold(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafc9768-a82a-4862-aef3-9e400808d636",
   "metadata": {},
   "source": [
    "### Model architecture and Training "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c2d2ea-0b32-4c00-a177-12e8422cef75",
   "metadata": {},
   "source": [
    "Both the hyperparameter tuning and training code are similar to the code in ``GNN.ipynb``. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4095b3-770c-4663-b55d-9bb17fc8cd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, dim_in, dim_h1, dim_h2, dim_out=2):\n",
    "        super().__init__()\n",
    "        self.linear1 = Linear(dim_in, dim_h1)\n",
    "        self.linear2 = Linear(dim_h1, dim_h2)\n",
    "        self.linear3 = Linear(dim_h2, dim_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)  \n",
    "        x = torch.relu(x)    \n",
    "        x = self.linear2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.linear3(x)\n",
    "        x = torch.softmax(x, dim=1)  # return probability of each class\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6fc7ec-9880-4d4e-a4b1-2d0548373d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, lr, weight_decay, weighted_loss, epochs=30):\n",
    "    global train_prediction, val_pred, train_loss, val_loss, train_acc, val_acc, mcc_final\n",
    "    train_prediction, val_pred = [], []\n",
    "    train_loss, val_loss, train_acc, val_acc = [], [], [], []\n",
    "\n",
    "    # weighted loss for imbalanced class\n",
    "    weights = torch.tensor([1, weighted_loss])  # class 1 is the minority class so it's higher weighted\n",
    "    weights = weights.to(torch.float)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(weight=weights)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    for i in range(len(train)): \n",
    "        print(f\"********** Fold {i+1} train data: **********\")\n",
    "        train_features = torch.tensor(df.iloc[train[i]][columns].values)\n",
    "        train_features = train_features.to(torch.float) \n",
    "        train_labels = torch.tensor(df.iloc[train[i]][\"label\"].values)\n",
    "        train_labels = train_labels.to(torch.long)\n",
    "\n",
    "        val_features = torch.tensor(df.iloc[val[i]][columns].values)\n",
    "        val_features = val_features.to(torch.float) \n",
    "        val_labels = torch.tensor(df.iloc[val[i]][\"label\"].values)\n",
    "        val_labels = val_labels.to(torch.long)\n",
    "\n",
    "        for epoch in range(epochs + 1):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(train_features)  # the features are the node and edge features\n",
    "            loss = loss_fn(output, train_labels)  # loss is based on edge labels\n",
    "            #loss_values.append(loss.detach().numpy()) don't have this\n",
    "\n",
    "            #prediction.append(output.argmax(1))  # maximum index in each row\n",
    "            #accuracy = torch.sum(torch.argmax(output, dim=1) == train_label) / len(train_label)\n",
    "            #acc.append(accuracy.detach().numpy())\n",
    "            loss.backward()  # backpropagation\n",
    "            optimizer.step()  # parameter update\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                accuracy = torch.sum(torch.argmax(output, dim=1) == train_labels) / len(train_labels)\n",
    "                train_prediction_ = output.argmax(1)\n",
    "                mcc_train = matthews_corrcoef(train_labels, train_prediction_)\n",
    "                \n",
    "                print(f\"Epoch: {epoch}\")\n",
    "                print(\" Train data: \")\n",
    "                print(f\"   Loss: {loss}\")\n",
    "                print(f\"   Accuracy: {accuracy}\") \n",
    "                print(f\"   MCC: {mcc_train}\")\n",
    "\n",
    "                val_out = model(val_features)\n",
    "                loss_ = loss_fn(val_out, val_labels)\n",
    "                val_accuracy = torch.sum(torch.argmax(val_out, dim=1) == val_labels) / len(val_labels)\n",
    "                val_pred_ = val_out.argmax(1)\n",
    "                val_mcc = matthews_corrcoef(val_labels, val_pred_)\n",
    "                \n",
    "                print(\"Validation data: \")\n",
    "                print(f\"   Loss: {loss_}\")\n",
    "                print(f\"   Accuracy: {val_accuracy}\")\n",
    "                print(f\"   MCC: {val_mcc}\")\n",
    "                \n",
    "                if epoch == 30:\n",
    "                    # append train data results\n",
    "                    train_loss.append(loss.detach().numpy())\n",
    "                    train_acc.append(accuracy.detach().numpy())\n",
    "                    train_prediction.append(output.argmax(1))\n",
    "\n",
    "                    # append validation data results                    \n",
    "                    val_loss.append(loss_.detach().numpy())\n",
    "                    val_acc.append(val_accuracy.detach().numpy())\n",
    "                    val_pred.append(val_out.argmax(1))    \n",
    "\n",
    "                    # only show the plots after hyperparameter tuning! \n",
    "                    cm = confusion_matrix(train_labels, train_prediction[i])\n",
    "                    cm2 = confusion_matrix(val_labels, val_pred[i])\n",
    "                    ConfusionMatrixDisplay(cm).plot() \n",
    "                    plt.savefig(f\"{visualizations}/NN Fold {i+1} Train.svg\")  \n",
    "                    ConfusionMatrixDisplay(cm2).plot()                                        \n",
    "                    plt.savefig(f\"{visualizations}/NN Fold {i+1} Validation.svg\")\n",
    "                    \n",
    "                # use MCC score to evaluate the model\n",
    "                if epoch == 30 and i == 9:   # assume that the last epoch and last fold has the best score\n",
    "                    mcc_final = matthews_corrcoef(val_labels, val_pred[i])  \n",
    "                    print(f\"    MCC Final: {mcc_final}\")\n",
    "        \n",
    "    return mcc_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4d6e58-5832-4178-9c3e-97295c1b6ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model):\n",
    "    global pred_test\n",
    "    pred_test = []\n",
    "\n",
    "    for i in range(len(test)):\n",
    "        print(f\"********** Fold {i+1} test data: **********\")\n",
    "        test_features = torch.tensor(df.iloc[test[i]][columns].values)\n",
    "        test_features = test_features.to(torch.float) \n",
    "        test_labels = torch.tensor(df.iloc[test[i]][\"label\"].values)\n",
    "        test_labels = test_labels.to(torch.long)\n",
    "\n",
    "        output = model(test_features)\n",
    "        pred_test.append(output.argmax(1))\n",
    "        #loss = loss_fn(output, test_labels)\n",
    "        accuracy = torch.sum(torch.argmax(output, dim=1) == test_labels) / len(test_labels)\n",
    "        mcc_test = matthews_corrcoef(test_labels, pred_test[i])\n",
    "        \n",
    "        print(\"Test data:\")\n",
    "        #print(f\"   Loss: {loss}\")\n",
    "        print(f\"   Accuracy: {accuracy}\")\n",
    "        print(f\"   MCC: {mcc_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b4bb03-141e-43cd-aa8f-eea400e26d8a",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fe98bc-aee0-4d33-bd06-6770085fc318",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'hidden_channels': [2, 4, 8],\n",
    "    'learning_rate': [0.001, 0.0001],\n",
    "    'weight_decay': [5e-4, 1e-4],\n",
    "    'weighted_loss': [100, 120, 140, 160, 180, 200],\n",
    "}\n",
    "\n",
    "grid = ParameterGrid(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfda144f-ae98-4e8a-8397-a109bb4bc9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding best hyperparameters\n",
    "best_val_acc = -np.inf\n",
    "best_params = None\n",
    "\n",
    "for params in grid:\n",
    "    print(f\"Hyperparameters: weighted_loss={params['weighted_loss']}, hidden_channels={params['hidden_channels']}, learning_rate={params['learning_rate']}, weight_decay={params['weight_decay']}\")\n",
    "    model = MLP(len(columns), params['hidden_channels']*2, params['hidden_channels'], 2)\n",
    "\n",
    "    fit(model, params['learning_rate'], params['weight_decay'], params['weighted_loss'])\n",
    "    \n",
    "    # find best hyperparameters using the MCC score\n",
    "    if mcc_final > best_val_acc:\n",
    "        best_val_acc = mcc_final\n",
    "        best_params = params\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}, Best Validation Accuracy: {best_val_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f6b490-e466-4560-91ae-8e50931d7c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Hyperparameters: {'hidden_channels': 8, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'weighted_loss': 180}, \n",
    "# Best Validation Accuracy: 0.03052772429762823"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feadd435-2530-487d-a5df-270ae96e218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = MLP(len(columns), 16, 8, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c597ef-dade-4d8c-bded-a46a632d4132",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(nn_model, 0.001, 0.0005, 160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb46cfb2-daa8-491b-bda2-f20757dd1e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(nn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf57354-079c-4b96-bc0d-99e9c7353d1b",
   "metadata": {},
   "source": [
    "### Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755528ca-bb5c-4788-b0c6-92a78d557b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm_test(n):\n",
    "    for i in range(n):\n",
    "        cm = confusion_matrix(test_labels[i], pred_test[i])\n",
    "        mcc = matthews_corrcoef(test_labels[i], pred_test[i])\n",
    "        print(mcc)\n",
    "        ConfusionMatrixDisplay(cm).plot()\n",
    "        plt.savefig(f\"{visualizations}/Confusion matrix NN - fold {i+1} Test.png\")\n",
    "cm_test(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ec7bed-28a2-476e-89e5-0a7f876c51c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(test_arr, pred_test):\n",
    "    #print(\"MCC scores: \")\n",
    "    global data\n",
    "    mcc_gcn, precision_gcn, recall_gcn, accuracy_gcn = [], [], [], []\n",
    "    for i in range(10):\n",
    "        mcc = matthews_corrcoef(test_arr[i], pred_test[i])\n",
    "        precision = precision_score(test_arr[i], pred_test[i])\n",
    "        recall = recall_score(test_arr[i], pred_test[i])\n",
    "        accuracy = accuracy_score(test_arr[i], pred_test[i])\n",
    "        #print(f\"Fold {i+1}: {mcc}\")\n",
    "        mcc_gcn.append(mcc)\n",
    "        precision_gcn.append(precision)\n",
    "        recall_gcn.append(recall)\n",
    "        accuracy_gcn.append(accuracy)\n",
    "    data = [mcc_gcn, precision_gcn, recall_gcn, accuracy_gcn]\n",
    "    return data\n",
    "    \n",
    "#evaluation(train_labels, train_prediction)\n",
    "#evaluation(val_labels, val_pred)\n",
    "evaluation(test_labels, pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e149e7-8ddb-45bb-8e34-ee81ee23b5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_columns = [\"MCC\", \"Precision\", \"Recall\", \"Accuracy\"]\n",
    "\n",
    "def export_results(model, data, columns):   \n",
    "    evaluation = \"../evaluation\"\n",
    "    if not os.path.exists(evaluation):\n",
    "        os.makedirs(evaluation)\n",
    "        \n",
    "    df = pd.DataFrame()\n",
    "    for i in range(len(data)):\n",
    "        df[columns[i]] = pd.Series(data[i])\n",
    "    \n",
    "    df.index += 1 \n",
    "    df.to_csv(f\"{evaluation}/{model}.csv\", index_label=\"ID\")\n",
    "    return df\n",
    "\n",
    "#export_results(\"NN_Train\", data, eval_columns) \n",
    "#export_results(\"NN_Validation\", data, eval_columns) \n",
    "export_results(\"NN_Test\", data, eval_columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6cf597-5946-4aec-b0f0-4e6ffa11e051",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
